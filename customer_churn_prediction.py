# -*- coding: utf-8 -*-
"""Customer_Churn_Prediction

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1CXnvkjXP6Sjj42HNGQxm4rw96AXSuSDO
"""

import pandas as pd  # To read the file
import numpy as np   # To perform Array Multiplication & to perform mathematical operation
import seaborn as sns  # For Advance visulization
import matplotlib.pyplot as plt  # For visulization

from sklearn.model_selection import train_test_split  # To split the data into x & y  axis
from sklearn.preprocessing import OneHotEncoder,LabelEncoder,OrdinalEncoder  # To convert String into numeric form
from sklearn.preprocessing import StandardScaler  # # It help in standized the data to mean = 0 & std = 1
from sklearn.preprocessing import MinMaxScaler  # To Bring the data into -1 & +1 format
from sklearn.feature_selection import SelectKBest # To select the best features
from sklearn.preprocessing import PowerTransformer # PowerTransformer is a data preprocessing technique
from sklearn.compose import ColumnTransformer #  It is used for data preprocessing and transformation of different subsets of columns in a dataset
from sklearn.pipeline import Pipeline,make_pipeline # make_pipeline is a convenience function in scikit-learn that simplifies the creation of a machine learning pipeline
from sklearn.metrics import accuracy_score  # To check the accuracy of the model
from sklearn.model_selection import GridSearchCV # To find the best tuning
from sklearn.decomposition import PCA # To Take best feature we use pca(Principal Component Analysis)
from sklearn.model_selection import cross_val_score # evaluating a model on each subset, and returning the evaluation scores
from sklearn.linear_model  import LogisticRegression # Logistic Regression is a statistical model used for binary classification in ML
from sklearn.tree import DecisionTreeClassifier # DecisionTreeClassifier is a algorithm of ML used for binary classification in ML
from sklearn.svm import SVC # SVC stands for Support Vector Classifier, which is a machine learning algorithm used for classification tasks
from sklearn.neighbors import KNeighborsClassifier #  Is a machine learning algorithm used for classification tasks
from sklearn.naive_bayes import BernoulliNB # Is a ml algorithm for classification task
from sklearn.linear_model import Perceptron # It is a single type of artifical neural network used for binary classification task
from sklearn.ensemble import RandomForestClassifier # RandomForestClassifier is a machine learning algorithm used for classification tasks
from sklearn.ensemble import VotingClassifier #  machine learning technique in which multiple models, such as classifiers or regressors, are combined to make predictions
from sklearn.ensemble import AdaBoostClassifier # AdaBoostClassifier is a machine learning ensemble method, specifically used for classification tasks.
from sklearn.ensemble import BaggingClassifier #  The BaggingClassifier is an ensemble machine learning technique that combines multiple base classifiers

# ANN(ARTIFICAL NEURAL NETWORK)
import tensorflow  # This library is import for Deep Learning
import tensorflow as tf # This library is import for Deep Learning
from tensorflow import keras # keras is a deep learning frame work
from tensorflow.keras import Sequential # Sequential typically refers to a type of neural network architecture used in deep learning
from tensorflow.keras.layers import Dense #  "dense" refers to a type of layer commonly used in deep learning models

"""## Data Preprocessing"""

df = pd.read_excel("/content/customer_churn_large_dataset.xlsx") # To Read a Excel

df.head() # To check the top 5 rows along with column's

df.isnull().sum() # To check the null values

print(df['Location'].unique())
print("The total numbers of state's is:",df['Location'].nunique())

df.describe() # To know the flow of the table

df.info() # To know the data types of the table

df.corr() # To knoe the correlation of the table

df = df.drop(columns=["CustomerID", "Name","Location"]) # removing the unnecessary column's

df = pd.get_dummies(data=df, columns=["Gender"], drop_first=True) # In this we are performing OneHotEncoder to convert "string" variable into "int"

"""## Let's perform EDA"""

sns.scatterplot(x = df['Subscription_Length_Months'],y = df['Monthly_Bill'],hue = df['Churn'])

plt.hist(x = df['Age'])

sns.heatmap(df[["Age","Monthly_Bill","Total_Usage_GB","Churn"]])

sns.pairplot(df[["Age","Monthly_Bill","Total_Usage_GB","Churn"]])

"""## Now lets check the outliers in the data"""

sns.boxplot(df['Age'])

sns.boxplot(df['Subscription_Length_Months'])

sns.boxplot(df['Monthly_Bill'])

sns.boxplot(df['Total_Usage_GB'])

"""## From the above diagram we can see there is no outliers in the data

## Now lets check the flow of the data
"""

sns.distplot(df["Age"])

sns.distplot(df["Subscription_Length_Months"])

sns.distplot(df["Monthly_Bill"])

sns.distplot(df["Total_Usage_GB"])

"""## From the above diagram we can clearly see that the data is normally distributed

## Now let's divide the data into train_test_split
"""

x = df.drop(columns="Churn")  # Independent columns
y = df.iloc[:,-1]   # Dependent columns

x_train,x_test,y_train,y_test = train_test_split(x,y,test_size = 0.2,random_state = 42) # spliting the data into x & y

print(x_train.shape)
print(y_test.shape)

sc = StandardScaler()  # To bring the data in between 0 & 1

x_train_sc = sc.fit_transform(x_train)  # scaling the values between 0 & 1 train data
x_test_sc = sc.transform(x_test) # scaling the values between 0 & 1 for test data

"""## There is no need for function transformation as your data is normally distributed

## Now Let's Apply Power Transformer (yeo Johnson Transform)
"""

pt = PowerTransformer()  # This is power transformer to enrich the data in more understanding able manner

x_train_pt = pt.fit_transform(x_train_sc)
x_test_pt = pt.transform(x_test_sc)

"""## There is no need for Feature construction so
## Let's move to Feature Extraction or Feature Selection(using PCA)
"""

pca = PCA(n_components=0.95) # Principle Components Analysis (to extract the important features and select imprtant feature)

x_train_pca = pca.fit_transform(x_train_pt)
x_test_pca = pca.transform(x_test_pt)

"""## Now Till here we had performed lot's of Feature Engineering work we had In Rich the data in a lot in Feature Engineering prospectively

## Now let's start Performing Model Building/Machine Learning Task

## First Lets Begin with LogisticRegression Machine Learning Algorithm
"""

lr = LogisticRegression()
lr.fit(x_train_pca,y_train)
y_pred = lr.predict(x_test_pca)

print("The Accuracy_Score of LogisticRegression is:",accuracy_score(y_pred,y_test))
print("The cross_val_score of LogisticRegression is:",cross_val_score(lr,x_train_pca,y_train,cv=5).mean())

"""## In this model we are using KNeighboursClassifiers as machine learning algorithm"""

kn = KNeighborsClassifier()
kn.fit(x_train_pca,y_train)
y_pred1 = kn.predict(x_test_pca)

print("The Accuracy_Score of KNeighboursClassifier is:",accuracy_score(y_pred1,y_test))
print("The cross_val_score of KNeighboursClassifier is:",cross_val_score(kn,x_train_pca,y_train,cv=5).mean())

"""## In this we are using RandomForestClassifier algorithm"""

rf = RandomForestClassifier()
rf.fit(x_train_pca,y_train)
y_pred2 = rf.predict(x_test_pca)

print("The Accuracy_Score of RandomForestClassifier is:",accuracy_score(y_pred2,y_test))
print("The cross_val_score of RandomForestClassifer is:",cross_val_score(rf,x_train_pca,y_train,cv=5).mean())

"""## In this we are using SVM algoritm"""

sv = SVC(probability=True)
sv.fit(x_train_pca,y_train)
y_predd = sv.predict(x_test_pca)

print("The Accuracy_Score of SVM is:",accuracy_score(y_predd,y_test))
print("The cross_val_score of SVM is:",cross_val_score(sv,x_train_pca,y_train,cv=5).mean())

"""## In this we are using perceptron algorithm"""

p = Perceptron()
p.fit(x_train_pca,y_train)
yy = p.predict(x_test_pca)

print("The Accuracy_Score of Perceptron is:",accuracy_score(yy,y_test))
print("The cross_val_score of Perceptron is:",cross_val_score(p,x_train_pca,y_train,cv=5).mean())

"""## In this we are using Naive Bayes Machine Learing Algorithm"""

br = BernoulliNB()
br.fit(x_train_pca,y_train)
y_pred_bern = br.predict(x_test_pca)

print("The Accuracy_Score of Bernoullic is:",accuracy_score(y_pred_bern,y_test))
print("The cross_val_score of Bernoullic is:",cross_val_score(br,x_train_pca,y_train,cv=5).mean())

"""## Now lets perform DecisionTreeClassifer Machine Learning Algorithm

"""

dt = DecisionTreeClassifier()
dt.fit(x_train_pca,y_train)
y_pred_tree = dt.predict(x_test_pca)

print("The Accuracy_Score of DecisionTreeClassifier is:",accuracy_score(y_pred_tree,y_test))
print("The cross_val_score of DecisionTreeClassifier is:",cross_val_score(dt,x_train_pca,y_train,cv=5).mean())

"""## Now let's perform the ensemble learning methods of Machine Learning.

## Let's Began with the most popular BoostingClassifier(ensemble)
"""

ada = AdaBoostClassifier(n_estimators=1,learning_rate=1.0)
ada.fit(x_train_pca,y_train)
y_pred_ada = ada.predict(x_test_pca)

print("The AccuracyScore of AdaBoostClassifier is:",accuracy_score(y_pred_ada,y_test))
print("The Cross_Val_Score of AdaBoostClassifier is:",cross_val_score(ada,x_train_pca,y_train,cv=5).mean())

"""## Now lets perform BaggingClassifier(ensemble)"""

bag = BaggingClassifier(n_estimators=50,estimator=SVC())
bag.fit(x_train_pca,y_train)
y_pred_bag = bag.predict(x_test_pca)

print("The AccuracyScore of BaggingClassifier is:",accuracy_score(y_pred_bag,y_test))
print("The Cross_Val_Score of BaggingClassifier is:",cross_val_score(bag,x_train_pca,y_train,cv=5).mean())

"""## Now lets perform VotingClassifier(ensemble) In this we will take take all algorithm prediction and give the output."""

cf1 = LogisticRegression()
cf2 = RandomForestClassifier()
cf3 = SVC(probability=True)

estimators = [("lr",cf1),("rf",cf2),("sv",cf3)]

vc = VotingClassifier(estimators=estimators,voting="soft")
vc.fit(x_train_pca,y_train)
y_pred_vc = vc.predict(x_test_pca)

print("The Accuracy_score of VotingClassifier is:",accuracy_score(y_pred_vc,y_test))
print("The cross_val_score of VotingClassifier is:",cross_val_score(vc,x_train_pca,y_train,cv=5).mean())

"""## NOW LET'S PREDICT WITH DEEP LEARNING MODEL(ANN)

## Now lets Build a ANN (Artificial Neural Networks) Model
"""

model = Sequential()
model.add(Dense(128,activation="relu",input_dim=5))
model.add(Dense(50,activation="relu"))
model.add(Dense(25,activation="relu"))
model.add(Dense(1,activation="sigmoid"))

model.summary()

model.compile(loss="binary_crossentropy",optimizer="Adam",metrics=["accuracy"])

history = model.fit(x_train_pca,y_train,epochs=10,batch_size=1000,validation_split=0.2)

plt.plot(history.history["loss"])
plt.plot(history.history["val_loss"])

plt.plot(history.history["accuracy"])
plt.plot(history.history["val_accuracy"])

y_log = model.predict(x_test_pca)

y_pred_dl = np.where(y_log>0.5,1,0)

accuracy_score(y_pred_dl,y_test)

